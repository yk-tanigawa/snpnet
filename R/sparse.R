defaultVariantFilter = function(snps_to_use_arg){
   # Default filter removes variants whose has more than 10% NAs in the training set
   snps_to_use_arg <- snps_to_use_arg %>% dplyr::filter(stats_pNAs < 0.1)
   return(snps_to_use_arg)
}


#' @export
snpnet2Base <- function(genotype.pfile, phenotype.file, phenotype, VariantFilter=defaultVariantFilter, GroupMap=NULL, family = NULL,
    covariates = NULL, sparse=TRUE, nlambda = 100, lambda.min.ratio = 1e-4, lambda = NULL, split.col = NULL,
    p.factor = NULL, status.col = NULL, mem = NULL, configs = NULL) {
    time.start <- Sys.time()
    snpnetLogger("Start snpnet", log.time = time.start)

    snpnetLogger("Preprocessing start..")

    ### --- Read genotype IDs --- ###
    ids <- list()
    phe <- list()
    ids[["psam"]] <- readIDsFromPsam(paste0(genotype.pfile, ".psam"))

    ### --- combine the specified configs with the default values --- ###
    if (!is.null(lambda))
        nlambda <- length(lambda)
    configs <- setupConfigs(configs, genotype.pfile, phenotype.file, phenotype, covariates,
        1, nlambda, split.col, p.factor, status.col, mem)
    ### --- Read phenotype file --- ###
    phe[["master"]] <- readPheMaster(phenotype.file, ids[["psam"]], family, covariates,
        phenotype, status.col, split.col, configs)

    ### --- infer family and update the configs --- ###
    if (is.null(family))
        family <- inferFamily(phe[["master"]], phenotype, status.col)
    configs <- updateConfigsWithFamily(configs, family)

    ### --- Process phenotypes --- ###
    if (family == "binomial") {
        # The input binary phenotype is coded as 2/1 (case/control) For glmnet, we map
        # this to 1/0 (case/control) The following expression will replace -9 (missing)
        # with -10, but the set of individuals with no-missing values are already
        # computed.
        if (min(phe[["master"]][[phenotype]], na.rm = T) >= 1 && max(phe[["master"]][[phenotype]],
            na.rm = T) <= 2) {
            phe[["master"]][[phenotype]] <- phe[["master"]][[phenotype]] - 1
        }
    }

    ### --- Define the set of individual IDs for training (and validation) set(s) ---
    validation <- (!is.null(split.col))
    if (validation) {
        splits <- c("train", "val")
        for (s in splits) {
            ids[[s]] <- phe[["master"]]$ID[phe[["master"]][[split.col]] == s]
        }
    } else {
        splits <- c("train")
        ids[["train"]] <- phe[["master"]]$ID
    }

    ### --- Prepare the feature matrix --- ###
    features <- list()
    for (s in splits) {
        phe[[s]] <- phe[["master"]][match(ids[[s]], phe[["master"]]$ID), ]
        rownames(phe[[s]]) <- phe[[s]]$ID
        if (length(covariates) > 0) {
            features[[s]] <- phe[[s]][, covariates, with = F]
        } else {
            features[[s]] <- NULL
        }
        if (configs[["verbose"]])
            snpnetLogger(sprintf("The number of individuals in %s set: %d", s, dim(phe[[s]])[1]))
    }

    ### --- Prepare the response --- ###
    response <- list()
    status <- list()
    pred <- list()
    for (s in splits) {
        response[[s]] <- phe[[s]][[phenotype]]
        if (family == "cox") {
            status[[s]] <- phe[[s]][[status.col]]
            response[[s]] <- survival::Surv(response[[s]], status[[s]])
        }
    }

    ### --- Read genotypes --- ###
    vars <- dplyr::mutate(dplyr::rename(data.table::fread(cmd = paste0(configs[["zstdcat.path"]],
        " ", paste0(genotype.pfile, ".pvar.zst"))), CHROM = "#CHROM"), VAR_ID = paste(ID,
        ALT, sep = "_"))$VAR_ID
    pvar <- pgenlibr::NewPvar(paste0(genotype.pfile, ".pvar.zst"))

    pgen <- list()
    samples_subset <- list()
    for (s in splits) {
        samples_subset[[s]] <- match(ids[[s]], ids[["psam"]])
        pgen[[s]] <- pgenlibr::NewPgen(paste0(genotype.pfile, ".pgen"), pvar = pvar,
            sample_subset = samples_subset[[s]])
    }
    pgenlibr::ClosePvar(pvar)

    snps_to_use <- computeSparseStats(genotype.pfile, phe[["train"]]$ID, configs = configs)


    snps_to_use <- VariantFilter(snps_to_use)
    if(!is.null(GroupMap)){
        gene_cumu <- GroupMap(snps_to_use)
        snpnetLogger("Solving a Group Lasso problem.")
    } else {
        snpnetLogger("Solving a Lasso problem.")
    }
    snpnetLoggerTimeDiff("Preprocessing end.", time.start, indent = 1)
    snpnetLogger(paste("Number of variants to use is", nrow(snps_to_use), "Training data size is", nrow(phe[['train']])))

    ### --- Fit a model using only the covariates
    offset <- list()
    if (family == "cox") {
        predictors = as.matrix(phe[['train']] %>%  dplyr::select(all_of(covariates)))
        glmmod <- myglmnet::myglmnet(predictors, response[['train']], family="cox", standardize=F, lambda=c(0))
        glmmod$family <- list("cox")
        glmmod$model <- c(phenotype, covariates)
        offset[['train']] <- as.double(predictors %*% glmmod$beta)
        if(validation) {
            offset[['val']] <-  as.matrix(phe[['val']] %>%  dplyr::select(all_of(covariates))) %*% glmmod$beta
        }
    } else {
        glmmod <- stats::glm(stats::as.formula(paste(phenotype, " ~ ", paste(c(1,
            covariates), collapse = " + "))), data = phe[["train"]], family = family)
    }

    group_reg = !is.null(GroupMap)
    if(group_reg){
        proxObj <- pgenlibr::NewProxObj(nrow(snps_to_use), gene_cumu)
    } else {
        proxObj <- pgenlibr::NewLassoObj(nrow(snps_to_use))
    }


    gaussian_response_sd <- NULL
    responseObj <- NULL
    # Run linear prediction
    if(family != "cox"){
        for (s in splits) {
            offset[[s]] <- stats::predict(glmmod, phe[[s]] %>% dplyr::select(all_of(covariates)))
        }
    }

    if (family == "gaussian") {
        gaussian_response_sd <- sd(glmmod$residuals)
        responseObj <- pgenlibr::NewResponseObj(glmmod$residuals/gaussian_response_sd,
            "gaussian")
    } else if (family == "binomial") {
        responseObj <- pgenlibr::NewResponseObj(response[['train']], "binomial", offset[['train']])
    } else if (family == "cox") {
        responseObj <- getCoxResponseObj(response[['train']], offset[['train']])
    }


    time.load.matrix <- Sys.time()
    snpnetLogger("Start loading training genotype matrix")
    if(sparse){
        if(nrow(snps_to_use) < 10000 || nrow(phe[['train']]) < 30000){
            warning("Data size too small. Dense representation will be used")
            sparse <- FALSE
        }
    }
    if(sparse){
        Xtrain <- try(pgenlibr::NewSparse(pgen[["train"]], snps_to_use$index))
        if(is(Xtrain, "try-error")){
            sparse <- FALSE
            warning("Loading sparse training matrix failed. This happens most likely because the reference allele is not the major allele, or some variants have large number of NAs. Use Dense instead.")
        }
    }

    if(sparse){
        MULT_FUN <- pgenlibr::SparseMultv
    } else {
        Xtrain <- pgenlibr::NewDense(pgen[["train"]], snps_to_use$index)
        MULT_FUN <- pgenlibr::DenseMultv
    }


    if(validation){
        Xval <- pgenlibr::NewDense(pgen[["val"]], snps_to_use$index, snps_to_use$stats_means)
    }
    snpnetLoggerTimeDiff("End loading genotype matrix", time.load.matrix, indent = 1)

    if (is.null(lambda)) {
        if(group_reg){
            lambda.max <- pgenlibr::ComputeLambdaMax(Xtrain, responseObj, gene_cumu)
        } else {
            lambda.max <- pgenlibr::ComputeLambdaMax(Xtrain, responseObj, seq(0, nrow(snps_to_use)))
        }
        full.lams <- exp(seq(from = log(lambda.max), to = log(lambda.max * lambda.min.ratio),
            length.out = nlambda))
    } else {
        full.lams <- lambda
    }

    metric.train <- rep(NA, length(full.lams))
    metric.val <- rep(NA, length(full.lams))
    max.metric.val <- -1


    if (validation) {
        lambda_schedule <- round(c(0, 0.05*(1:20)) * length(full.lams))
    } else {
        lambda_schedule <- c(0, length(full.lams))
    }

    beta = NULL
    early.stop = FALSE

    for (i in 1:(length(lambda_schedule) - 1)) {
        time.iter <- Sys.time()
        snpnetLogger(paste("Iteration", i))
        lambda_start_ind <- lambda_schedule[i] + 1
        lambda_end_ind <- lambda_schedule[i + 1]
        lambda_this_iter <- full.lams[lambda_start_ind:lambda_end_ind]
        result <- pgenlibr::FitProx(Xtrain, proxObj, responseObj, lambda_this_iter)
        if(family == "gaussian") {
            result = result * gaussian_response_sd
        }
        beta <- cbind(beta, result)
        snpnetLogger("Evaluating training metric")
        ### Compute training metric
        pred.train = matrix(nrow=length(response[["train"]]), ncol=ncol(result))
        for (j in 1:(ncol(result))) {
            pred.train[, j] <- MULT_FUN(Xtrain, result[, j])
        }

        pred.train <- sweep(pred.train, 1,  offset[["train"]], "+")
        metric.train[lambda_start_ind:lambda_end_ind] <- computeMetric(pred.train, response[["train"]],
            configs[["metric"]])

        if (validation) {
            snpnetLogger("Evaluating validation metric")
            pred.val = matrix(nrow=length(response[["val"]]), ncol=ncol(result))
            for (j in 1:(ncol(result))) {
                pred.val[,j] <- pgenlibr::DenseMultv(Xval, result[, j])
            }

            pred.val <- sweep(pred.val, 1,  offset[["val"]], "+")
            metric.val[lambda_start_ind:lambda_end_ind] <- computeMetric(pred.val, response[["val"]],
                configs[["metric"]])

            print(metric.train[1:lambda_end_ind])
            print(metric.val[1:lambda_end_ind])

            if(early.stop) {
                snpnetLoggerTimeDiff("Early stopping condition reached", time.start, indent = 1)
                break
            }

            max.metric.val <- max(metric.val, na.rm = T)
            # Update early.stop after checking to go one iteration further in the path
            early.stop = metric.val[lambda_end_ind] < max.metric.val

        }
        snpnetLoggerTimeDiff(paste("Iteration", i, "done"), time.iter, indent = 1)
    }

    rownames(beta) <- snps_to_use$original_ID
    metric.train = metric.train[1:lambda_end_ind]
    metric.val = metric.val[1:lambda_end_ind]

    return(list(beta=beta, covs_fit=glmmod, snps_used=snps_to_use, metric.train=metric.train, metric.val=metric.val, lambda=full.lams[1:lambda_end_ind]))

}


#' @export
sparse_snpnet <- function(genotype.pfile, phenotype.file, phenotype, group_map, family = NULL,
    covariates = NULL, sparse=TRUE, nlambda = 100, lambda.min.ratio = 1e-4, lambda = NULL, split.col = NULL,
    p.factor = NULL, status.col = NULL, mem = NULL, configs = NULL, variant_filter=NULL) {

        ### The mapping file must have these columns
    gene_map <- data.table::fread(group_map, select = c("#CHROM", "POS", "SYMBOL", "Csq"), colClasses=c(POS="integer"))
    names(gene_map)[1] <- "CHROM"
    names(gene_map)[3] <- "gene_symbol"

    gene_map$CHROM[gene_map$CHROM == "X"] <- "23"
    gene_map$CHROM[gene_map$CHROM == "Y"] <- "24"
    gene_map$CHROM <- as.integer(gene_map$CHROM)
    unique_chrom <- unique(gene_map$CHROM)
    if (max(unique_chrom) != length(unique_chrom)) {
        stop("The chromosome must be stored in the order 1,2,3,..., X, Y")
    }

    cumu_chrom <- integer(length(unique_chrom) + 1)
    for (i in (1:length(unique_chrom))) {
        ind <- which(gene_map$CHROM == i)
        cumu_chrom[i + 1] <- cumu_chrom[i] + length(ind)

        requirement <- all(diff(gene_map$POS[ind]) >= 0) && (ind[1] == cumu_chrom[i] + 1)
        if (!requirement) {
            stop("The gene mapping must have all SNPs on the same chromosome stored contiguously, and the position of the SNPs within the same chromosome must be non-decreasing")
        }
    }


    VariantFilter = function(snps_to_use_arg){
        snps_to_use_arg <- snps_to_use_arg %>% dplyr::filter((NON_REF_CT >= 3) & (stats_pNAs < 0.1) & (miss_over_non_ref < 10))

        if(!is.null(variant_filter)) {
            vfilter = data.table::fread(variant_filter, select="ID")
            snps_to_use_arg <- snps_to_use_arg %>% dplyr::filter(original_ID %in% vfilter$ID)
        }

        snps_to_use_arg <- snps_to_use_arg %>% dplyr::select(c("#CHROM", "POS", "index", "NON_REF_CT", "stats_means", "original_ID"))
        names(snps_to_use_arg)[1] <- "CHROM"
        snps_to_use_arg$CHROM[snps_to_use_arg$CHROM == "X"] <- "23"
        snps_to_use_arg$CHROM[snps_to_use_arg$CHROM == "Y"] <- "24"
        snps_to_use_arg <- snps_to_use_arg[, CHROM:=as.integer(CHROM)]

        snps_gene_ind <- pgenlibr::match_sorted_snp(snps_to_use_arg$CHROM, snps_to_use_arg$POS,
        gene_map$POS, cumu_chrom)

        # Just for testing,
        if(!all(snps_to_use_arg$POS == gene_map$POS[snps_gene_ind])){
            stop("something is wrong, most likely the group mapping file does not contain all the variant in the pgen file.")
        }
        snps_to_use_arg$gene <- gene_map$gene_symbol[snps_gene_ind]
        snps_to_use_arg$Csq <- gene_map$Csq[snps_gene_ind]

        # Only use autosome
        snps_to_use_arg <- snps_to_use_arg %>% dplyr::filter(CHROM < 23) %>% dplyr::filter(gene !=
            "" & (Csq %in% c("ptv", "pav")))
        # snps_to_use = snps_to_use %>% filter(Csq %in% c('ptv', 'pav'))

        genes_with_comma <- grepl(",", snps_to_use_arg$gene, fixed = TRUE)
        if (any(genes_with_comma)) {
            warning("Some SNPs are mapped to multiple genes. The first gene symbols will be used to group these SNPs")
            snps_to_use_arg$gene[genes_with_comma] <- sapply(strsplit(snps_to_use_arg$gene[genes_with_comma],
                ","), "[", 1)
        }

        unique_genes <- unique(snps_to_use_arg$gene)
        snps_to_use_arg$gene_order <- match(snps_to_use_arg$gene, unique_genes)
        snps_to_use_arg <- snps_to_use_arg %>% dplyr::arrange(gene_order)
        return(snps_to_use_arg)
    }

    GroupMap = function(snps_to_use_arg){
        gene_cumu <- snps_to_use_arg %>% dplyr::count(gene_order)
        gene_cumu <- c(0, cumsum(gene_cumu$n))
        return(gene_cumu)
    }


    snpnet2Base(genotype.pfile, phenotype.file, phenotype, VariantFilter, GroupMap, family,
    covariates, sparse, nlambda, lambda.min.ratio, lambda, split.col,
    p.factor, status.col, mem, configs)

}